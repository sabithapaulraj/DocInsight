{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9117c36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: C:\\Users\\SEC\\OneDrive\\Desktop\\docinsight\\notebooks\n",
      "PDF path: C:\\Users\\SEC\\OneDrive\\Desktop\\docinsight\\data\\raw\\tables-charts.pdf\n",
      "Exists: True\n",
      "Page image dir: C:\\Users\\SEC\\OneDrive\\Desktop\\docinsight\\data\\page_images\n",
      "Processed dir: C:\\Users\\SEC\\OneDrive\\Desktop\\docinsight\\notebooks\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "cwd = Path().resolve()\n",
    "print(\"CWD:\", cwd)\n",
    "\n",
    "# Locate PDF (works whether CWD is project root or /notebooks)\n",
    "pdf_path = cwd / \"data\" / \"raw\" / \"tables-charts.pdf\"\n",
    "if not pdf_path.exists():\n",
    "    pdf_path = cwd.parent / \"data\" / \"raw\" / \"tables-charts.pdf\"\n",
    "\n",
    "print(\"PDF path:\", pdf_path)\n",
    "print(\"Exists:\", pdf_path.exists())\n",
    "\n",
    "# Directories for images and processed data\n",
    "page_img_dir = (cwd / \"data\" / \"page_images\")\n",
    "if not page_img_dir.exists():\n",
    "    page_img_dir = (cwd.parent / \"data\" / \"page_images\")\n",
    "\n",
    "page_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processed_dir = cwd / \"data\" / \"processed\"\n",
    "if not processed_dir.exists():\n",
    "    processed_dir = cwd.parent / \"data\" / \"processed\"\n",
    "\n",
    "print(\"Page image dir:\", page_img_dir)\n",
    "print(\"Processed dir:\", processed_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e046f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages in PDF: 14\n",
      "Saved: page0.png\n",
      "Saved: page1.png\n",
      "Saved: page2.png\n",
      "Saved: page3.png\n",
      "Saved: page4.png\n",
      "Saved: page5.png\n",
      "Saved: page6.png\n",
      "Saved: page7.png\n",
      "Saved: page8.png\n",
      "Saved: page9.png\n",
      "Saved: page10.png\n",
      "Saved: page11.png\n",
      "Saved: page12.png\n",
      "Saved: page13.png\n"
     ]
    }
   ],
   "source": [
    "doc = fitz.open(pdf_path)\n",
    "print(\"Pages in PDF:\", len(doc))\n",
    "\n",
    "for page_index in range(len(doc)):\n",
    "    page = doc[page_index]\n",
    "    pix = page.get_pixmap(dpi=150)  # 150 dpi is usually enough\n",
    "    out_path = page_img_dir / f\"page{page_index}.png\"\n",
    "    pix.save(out_path)\n",
    "    print(\"Saved:\", out_path.name)\n",
    "\n",
    "doc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a38c501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BLIP model: Salesforce/blip-image-captioning-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676c59550ef247dcb1de5dfb7fddf652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SEC\\OneDrive\\Desktop\\docinsight\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SEC\\.cache\\huggingface\\hub\\models--Salesforce--blip-image-captioning-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1318d122a53241409cc08d92a4833ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ab5740d85e4df2b45dec6dd7787def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdc5a61b7514d05a9cd4b7d860fd7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3713b335b7843bfb4374e550be48ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5c4739e07a48fdbda1ef48f9ab2c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e086a06d0dd45cda9b3a572887da172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLIP model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a634d6951174eeaae682e1abcab2529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blip_model_name = \"Salesforce/blip-image-captioning-base\"\n",
    "print(\"Loading BLIP model:\", blip_model_name)\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(blip_model_name)\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(blip_model_name)\n",
    "\n",
    "print(\"BLIP model loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb928e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found page images: 14\n",
      "page0.png → a table of contents for a table of contents\n",
      "page1.png → a table of contents for the text and the text\n",
      "page2.png → a table of the number and type of the elements in the periodics\n",
      "page3.png → a table with the number of the numbers in each column\n",
      "page4.png → a graph graphing graphing graphing graphing graphing graphing graphing graphing graphing graph\n",
      "page5.png → nci class 12 math question paper\n",
      "page6.png → a graph plot with a line graph\n",
      "page7.png → a diagram of the effect of the effect of the effect of the effect of the effect of the effect of\n",
      "page8.png → a diagram of the number of different types of the genome\n",
      "page9.png → a diagram of a block diagram\n",
      "page10.png → a diagram of a flow flow diagram\n",
      "page11.png → a flow diagram for a flow flow\n",
      "page12.png → a sample of a research paper\n",
      "page13.png → a document with the title title and title title\n",
      "Chart chunks shape: (14, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>page_number</th>\n",
       "      <th>text</th>\n",
       "      <th>char_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pageimg_0</td>\n",
       "      <td>chart</td>\n",
       "      <td>0</td>\n",
       "      <td>a table of contents for a table of contents</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pageimg_1</td>\n",
       "      <td>chart</td>\n",
       "      <td>1</td>\n",
       "      <td>a table of contents for the text and the text</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pageimg_2</td>\n",
       "      <td>chart</td>\n",
       "      <td>2</td>\n",
       "      <td>a table of the number and type of the elements...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pageimg_3</td>\n",
       "      <td>chart</td>\n",
       "      <td>3</td>\n",
       "      <td>a table with the number of the numbers in each...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pageimg_4</td>\n",
       "      <td>chart</td>\n",
       "      <td>4</td>\n",
       "      <td>a graph graphing graphing graphing graphing gr...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunk_id chunk_type  page_number  \\\n",
       "0  pageimg_0      chart            0   \n",
       "1  pageimg_1      chart            1   \n",
       "2  pageimg_2      chart            2   \n",
       "3  pageimg_3      chart            3   \n",
       "4  pageimg_4      chart            4   \n",
       "\n",
       "                                                text  char_len  \n",
       "0        a table of contents for a table of contents        43  \n",
       "1      a table of contents for the text and the text        45  \n",
       "2  a table of the number and type of the elements...        63  \n",
       "3  a table with the number of the numbers in each...        53  \n",
       "4  a graph graphing graphing graphing graphing gr...        94  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_captions = []\n",
    "\n",
    "image_files = sorted(\n",
    "    [p for p in page_img_dir.iterdir() if p.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]],\n",
    "    key=lambda p: int(p.stem.replace(\"page\", \"\"))  # sort by page number\n",
    ")\n",
    "\n",
    "print(\"Found page images:\", len(image_files))\n",
    "\n",
    "for img_path in image_files:\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    out = blip_model.generate(**inputs, max_new_tokens=40)\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    page_num = int(img_path.stem.replace(\"page\", \"\"))\n",
    "\n",
    "    print(f\"{img_path.name} → {caption}\")\n",
    "\n",
    "    page_captions.append({\n",
    "        \"chunk_id\": f\"pageimg_{page_num}\",\n",
    "        \"chunk_type\": \"chart\",          # treat page-level visual as a chart/figure chunk\n",
    "        \"page_number\": page_num,\n",
    "        \"text\": caption,\n",
    "        \"char_len\": len(caption)\n",
    "    })\n",
    "\n",
    "df_chart_chunks = pd.DataFrame(page_captions)\n",
    "print(\"Chart chunks shape:\", df_chart_chunks.shape)\n",
    "df_chart_chunks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c91dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing master chunks: (73, 7)\n",
      "New master shape: (87, 7)\n",
      "chunk_type\n",
      "text     65\n",
      "chart    14\n",
      "table     8\n",
      "Name: count, dtype: int64\n",
      "Saved updated master chunks to: C:\\Users\\SEC\\OneDrive\\Desktop\\docinsight\\notebooks\\data\\processed\\tables-charts_master_chunks.csv\n"
     ]
    }
   ],
   "source": [
    "# Load current master chunks (text + tables)\n",
    "master_path = processed_dir / \"tables-charts_master_chunks.csv\"\n",
    "\n",
    "if master_path.exists():\n",
    "    df_master = pd.read_csv(master_path)\n",
    "    print(\"Loaded existing master chunks:\", df_master.shape)\n",
    "else:\n",
    "    # Fallback: if master doesn't exist yet, try loading plain text chunks\n",
    "    chunks_path = processed_dir / \"tables-charts_chunks.csv\"\n",
    "    df_master = pd.read_csv(chunks_path)\n",
    "    df_master[\"chunk_type\"] = \"text\"\n",
    "    df_master[\"chunk_id\"] = df_master[\"chunk_id\"].astype(str)\n",
    "    print(\"Loaded text-only chunks:\", df_master.shape)\n",
    "\n",
    "# Append chart/page-image caption chunks\n",
    "df_master = pd.concat([df_master, df_chart_chunks], ignore_index=True)\n",
    "df_master = df_master.reset_index(drop=True)\n",
    "\n",
    "print(\"New master shape:\", df_master.shape)\n",
    "print(df_master[\"chunk_type\"].value_counts())\n",
    "\n",
    "# Save updated master file\n",
    "df_master.to_csv(master_path, index=False)\n",
    "print(\"Saved updated master chunks to:\", master_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3fb41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462d452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1cf03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
